# need 8 gpus

project: DTT
save_path: DTT_ProntoQA
name: prontoqa-dtt

only_eval: False

save_only_improve: False
model_id: openai-community/gpt2
load_model_path: None
seed: 0
resume: 0
bf16: False
train_path: data/prontoqa_train.json
val_path: data/prontoqa_valid.json
per_device_train_batch_size: 16  # Adjusted for 8 GPUs (16 Ã— 8 = 128)
debug: False
gradient_accumulation_steps: 1
num_train_epochs: 50
lr: !!float "1e-4"
weight_decay: 0.01
save_steps: 500
eval_steps: 500